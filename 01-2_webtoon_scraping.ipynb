{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9330e36",
   "metadata": {},
   "source": [
    "### 네이버 웹툰 1개의 회차에 대한 Image 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0949b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "def download_one_episode(title, no, url):\n",
    "    req_header = {\n",
    "        \"referer\": url,\n",
    "        \"User-Agent\": \"Mozilla/5.0\",  # UA 추가 (웹툰 서버 보호용)\n",
    "    }\n",
    "    res = requests.get(url,headers=req_header)\n",
    "\n",
    "    if res.ok:\n",
    "        html = res.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        #이미지 src 추출\n",
    "        img_tags = soup.select(\"img[src*='_IMAG01']\")\n",
    "        img_url_list = [img['src'] for img in img_tags if img.has_attr('src')]\n",
    "\n",
    "        print(f\"img_tags 수: {len(img_tags)}\") \n",
    "        imgdir_name = os.path.join('img', title, str(no))\n",
    "        if not os.path.isdir(imgdir_name):\n",
    "            os.makedirs(imgdir_name)  # 하위경로까지 생성\n",
    "\n",
    "        for img_url in img_url_list:\n",
    "            img_res = requests.get(img_url, headers=req_header)\n",
    "            if img_res.ok:\n",
    "                img = img_res.content\n",
    "                file_name = os.path.basename(img_url)\n",
    "                file_path = os.path.join(imgdir_name, file_name)\n",
    "\n",
    "                with open(file_path, \"wb\") as file:\n",
    "                    file.write(img)\n",
    "                print(f\"Writing to {file_path}\")\n",
    "            else:\n",
    "                print(f\"Error Code = {res.status_code}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error Code = {res.status_code}\")\n",
    "\n",
    "\n",
    "download_one_episode(\n",
    "    '쌉초의난',\n",
    "    '92',\n",
    "    'https://comic.naver.com/webtoon/detail?titleId=823195&no=92&week=wed'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26104774",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_one_episode(\n",
    "    '쌉초의난',\n",
    "    '93',\n",
    "    'https://comic.naver.com/webtoon/detail?titleId=823195&no=93&week=wed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8045bf",
   "metadata": {},
   "source": [
    "#### 다른 코드로 풀어봄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea052b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "def download_one_episode(title,no,url) :\n",
    "    req_header = {'referer':url}\n",
    "    res= requests.get(url)\n",
    "    \n",
    "    if res.ok :\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        \n",
    "        img_tags = soup.select(\"img[src*='IMAG01']\")\n",
    "        imgurl_list = [img['src'] for img in img_tags]\n",
    "        \n",
    "        if img_tags :\n",
    "            save_dir = Path('img')/title /str(no)\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for idx,img_url in enumerate(imgurl_list,1) :\n",
    "            res=requests.get(img_url,headers=req_header)\n",
    "            res.raise_for_status()\n",
    "            \n",
    "            file_name = Path(img_url).name\n",
    "            save_path = save_dir / file_name\n",
    "            save_path.write_bytes(res.content)\n",
    "            print(f'다운로드 완료: {save_path} ({save_path.stat().st_size:,} bytes)')\n",
    "            \n",
    "            \n",
    "download_one_episode('쌉초의난',94,'https://comic.naver.com/webtoon/detail?titleId=823195&no=94&week=wed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399014ba",
   "metadata": {},
   "source": [
    "### 하나의 웹툰과 여러 개의 회차에 대한 Image 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9401c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def download_all_episode(title,episode_url):\n",
    "    parsed_url = urlparse(episode_url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    title_id = query_params.get('titleId', [''])[0]\n",
    "\n",
    "    api_url = f'https://comic.naver.com/api/article/list?titleId={title_id}&page=1'\n",
    "               #https://comic.naver.com/webtoon/detail?titleId=826419&no=46\n",
    "    res = requests.get(api_url)\n",
    "    print(res.status_code)    \n",
    "    if res.ok:\n",
    "        #pprint(res.json()['articleList'])\n",
    "        for article in res.json()['articleList']:\n",
    "            no = article['no']\n",
    "            detail_url = f'https://comic.naver.com/webtoon/detail?titleId={title_id}&no={no}'\n",
    "            print(detail_url)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__': \n",
    "    download_all_episode('대학일기','https://comic.naver.com/webtoon/list?titleId=679519')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f369281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "\"\"\"url에 titleId를 반환하는 함수\"\"\"\n",
    "def get_title_id(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    title_id = query_params.get('titleId', [''])[0]\n",
    "    return title_id\n",
    "\n",
    "#테스트 하기\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=679519'\n",
    "print(get_title_id(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab53d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pages(total_items, items_per_page=20):\n",
    "    \"\"\"총 페이지 수 계산 함수\"\"\"\n",
    "    return (total_items + items_per_page - 1) // items_per_page\n",
    "\n",
    "# 예제 사용\n",
    "total_items = 49\n",
    "items_per_page = 20\n",
    "\n",
    "total_pages = calculate_pages(total_items, items_per_page)\n",
    "print(f\"총 {total_items}개의 항목을 {items_per_page}개씩 출력할 때 필요한 페이지 수: {total_pages}\")\n",
    "# 출력: 총 49개의 항목을 20개씩 출력할 때 필요한 페이지 수: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865d3fe",
   "metadata": {},
   "source": [
    "### 하나의 웹툰과 여러 개의 회차에 대한 Image 다운로드 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_all_episode(title,episode_url):\n",
    "    title_id = get_title_id(episode_url)\n",
    "\n",
    "    ajax_url = f'https://comic.naver.com/api/article/list?titleId={title_id}'               \n",
    "    res = requests.get(ajax_url)\n",
    "\n",
    "    if res.ok:\n",
    "        total_count = res.json()['totalCount']\n",
    "        #for count in range(calculate_pages(total_count)):\n",
    "        page = 1 \n",
    "        req_param = { \"page\": page}\n",
    "        print(req_param)\n",
    "        res = requests.get(ajax_url, params=req_param)\n",
    "        for article in res.json()['articleList']:\n",
    "            no = article['no']\n",
    "            detail_url = f'https://comic.naver.com/webtoon/detail?titleId={title_id}&no={no}'\n",
    "            print(detail_url)\n",
    "            \n",
    "            download_one_episode(title,no,detail_url)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    download_all_episode('대학일기','https://comic.naver.com/webtoon/list?titleId=679519')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
